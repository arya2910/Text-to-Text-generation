{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO7bqg0YAjND39PK5ar+DOe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arya2910/Text-to-Text-generation/blob/main/texttotext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP-NQ7kDydUX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/jokes.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "hhWTkhxk0QSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Convert list of strings to single string\n",
        "text = ' '.join([str(x) for x in df['Question']])\n",
        "\n",
        "# Define a function to clean the text\n",
        "def clean_text(text):\n",
        "    # Remove unwanted characters and convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "    # Remove digits\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if not word in stop_words]\n",
        "    # Join tokens into a string\n",
        "    text = ' '.join(tokens)\n",
        "    return text"
      ],
      "metadata": {
        "id": "HH8doNiD2AQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data_x = []\n",
        "for i in range(len(df['Question'])):\n",
        "    cleaned_data_x.append(clean_text(df['Question'][i]))"
      ],
      "metadata": {
        "id": "yqLs2HlX4Trp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data_y = []\n",
        "for i in range(len(df['Answer'])):\n",
        "    cleaned_data_y.append(clean_text(df['Answer'][i]))"
      ],
      "metadata": {
        "id": "u5-viHHmcplS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(cleaned_data_x))\n",
        "print(len(cleaned_data_y))"
      ],
      "metadata": {
        "id": "-nKfjRtxNHmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, TimeDistributed,Activation, concatenate\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import dot\n",
        "import numpy\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "b9KIy2cw7e5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 50\n",
        "max_output_length = 50\n",
        "\n",
        "tokenizer_x = Tokenizer()\n",
        "tokenizer_x.fit_on_texts(cleaned_data_x)\n",
        "input_sequences = tokenizer_x.texts_to_sequences(cleaned_data_x)\n",
        "print(input_sequences)\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
        "print(encoder_inputs[0])\n",
        "input_vocab_size = len(tokenizer_x.word_index) + 1\n",
        "print(len(tokenizer_x.word_index))"
      ],
      "metadata": {
        "id": "taYLHkVhD8-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_y = Tokenizer()\n",
        "tokenizer_y.fit_on_texts(cleaned_data_y)\n",
        "output_sequences = tokenizer_y.texts_to_sequences(cleaned_data_y)\n",
        "decoder_inputs = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')\n",
        "output_vocab_size= len(tokenizer_y.word_index) + 1"
      ],
      "metadata": {
        "id": "RgrcQtVLD-QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoder_inputs))\n",
        "print(len(decoder_inputs))"
      ],
      "metadata": {
        "id": "X5JEkrmQinpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "latent_dim = 256\n",
        "\n",
        "encoder_inputs = Input(shape=(max_input_length,))\n",
        "print(encoder_inputs)\n",
        "encoder_embedding = Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "EQCFVvaEECbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(max_output_length,))\n",
        "decoder_embedding = Embedding(output_vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)"
      ],
      "metadata": {
        "id": "FVL-AHv2EFBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = dot([decoder_outputs, encoder_outputs], axes=[2, 2])\n",
        "attention = Activation('softmax', name='attention')(attention)\n",
        "\n",
        "context = dot([attention, encoder_outputs], axes=[2, 1])\n",
        "decoder_combined_context = concatenate([context, decoder_outputs])\n",
        "\n",
        "decoder_dense = TimeDistributed(Dense(output_vocab_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_combined_context)"
      ],
      "metadata": {
        "id": "B-pIUakJELiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Train the model\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Pu0drs-eEOcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "encoder_inputs_np = np.array(encoder_inputs)\n",
        "decoder_inputs_np = np.array(decoder_inputs)\n",
        "decoder_outputs_np = np.array(decoder_outputs)\n",
        "\n",
        "model.fit([tf.convert_to_tensor(encoder_inputs_np), tf.convert_to_tensor(decoder_inputs_np)], \n",
        "          tf.convert_to_tensor(decoder_outputs_np),\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "id": "Rn1UoPl8h_-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([encoder_inputs, decoder_inputs], decoder_outputs,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "n_8EJljGFQ-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "sentences = tokenized_data # assuming clean_text is defined beforehand\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=70, padding='post')\n",
        "print(len(padded_sequences))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "yWAvC08qeZzZ"
      }
    }
  ]
}